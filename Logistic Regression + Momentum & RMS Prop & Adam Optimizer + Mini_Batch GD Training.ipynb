{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqncjYB3RX-l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqEldyUFRd_Q",
        "outputId": "cbd10556-3e49-4afb-929e-69df6e5e7883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (60000, 28, 28)\n",
            "Y_train: (60000,)\n",
            "X_test:  (10000, 28, 28)\n",
            "Y_test:  (10000,)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# Importing MNIST Dataset\n",
        "(X_train, Y_train) , (X_test, Y_test) = mnist.load_data()\n",
        "print('X_train: ' + str(X_train.shape))\n",
        "print('Y_train: ' + str(Y_train.shape))\n",
        "print('X_test:  ' + str(X_test.shape))\n",
        "print('Y_test:  ' + str(Y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDQimRMBUjyU"
      },
      "outputs": [],
      "source": [
        "# Filtering the data to use only digit 0 and digit 1\n",
        "train_filter = np.where((Y_train == 0 ) | (Y_train == 1))\n",
        "test_filter = np.where((Y_test == 0) | (Y_test == 1))\n",
        "\n",
        "X_train , X_test = X_train[train_filter] , X_test[test_filter]\n",
        "Y_train , Y_test = Y_train[train_filter] , Y_test[test_filter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK5HmtfLUVx7",
        "outputId": "68ed2b4d-141f-4eb4-9a5a-4ae1a6fa5644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K0ShZSXSaCS",
        "outputId": "d51a707f-a1d5-4e67-f550-17ee2544f97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 ... 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QC3OE0_Sn4o"
      },
      "outputs": [],
      "source": [
        "# Standardization of data\n",
        "X_train = ((X_train - np.mean(X_train , axis = 0)) / (np.std(X_train , axis = 0)+18e-1))\n",
        "X_test = ((X_test -  np.mean(X_test , axis = 0)) / (np.std(X_test , axis = 0)+18e-1))\n",
        "\n",
        "\"\"\"\n",
        "Below is supposed the right way to standardize the data. We calculated the mean and std of the X_train. Then, we used it in both X_train and X_test\n",
        "The question is why we used the mean and std of X_train in the standardization of X_test. beacuse, since X_test has less data than X_train and X_test could\n",
        "contain outliers or repeated data therefore, it will be best if we standardize based on the majority of the data which is X_train\n",
        "\n",
        "mean = np.mean(X_train , axis = 0)\n",
        "std = np.std(X_train , axis = 0)\n",
        "X_train = (X_train - mean) / (std)\n",
        "X_test = (X_test - mean) / (std)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcoBhsKyvEmZ",
        "outputId": "ee0a76ad-d961-4783-c86c-902430ee354e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (12665, 784)\n",
            "Y_train: (12665,)\n",
            "X_test:  (2115, 784)\n",
            "Y_test:  (2115,)\n",
            "12665\n"
          ]
        }
      ],
      "source": [
        "# Reshaping the data to use it as 2D not 3D\n",
        "X_train = X_train.reshape(X_train.shape[0] , -1)\n",
        "X_test = X_test.reshape(X_test.shape[0] , -1)\n",
        "print('X_train: ' + str(X_train.shape))\n",
        "print('Y_train: ' + str(Y_train.shape))\n",
        "print('X_test:  ' + str(X_test.shape))\n",
        "print('Y_test:  ' + str(Y_test.shape))\n",
        "print(len(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDeTO_KgnE4a"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy\n",
        "def accuracy(predict,real,normalize=True):\n",
        "  return (np.sum(predict == real) / len(real)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Parameters needed for optimizers\n",
        "pre_v_dw , pre_v_db = np.zeros(X_train.shape[1]) , 0\n",
        "pre_m_dw , pre_m_db = np.zeros(X_train.shape[1]) , 0"
      ],
      "metadata": {
        "id": "_3aUgFIo_Lri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the momentum optimizer\n",
        "def momentum(w , b , dw , db , t , beta1):\n",
        "  global pre_m_dw\n",
        "  global pre_m_db\n",
        "  m_dw = beta1 * pre_m_dw + (1 - beta1) * (dw) #Weights\n",
        "  m_db = beta1 * pre_m_db + (1 - beta1) * (db) #Bias\n",
        "\n",
        "  pre_v_dw = m_dw.copy()\n",
        "  pre_v_db = m_db.copy()\n",
        "\n",
        "  # bias correction\n",
        "  m_dw = m_dw / (1 - beta1**t)\n",
        "  m_db = m_db / (1 - beta1**t)\n",
        "\n",
        "  return m_dw , m_db"
      ],
      "metadata": {
        "id": "OVwoFUh1V3S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the RMS prop optimizer\n",
        "def rms_prop(w , b , dw , db , t , beta2):\n",
        "  global pre_v_dw\n",
        "  global pre_v_db\n",
        "\n",
        "  v_dw = beta2 * pre_v_dw + (1 - beta2) * (dw**2) #Weights\n",
        "  v_db = beta2 * pre_v_db + (1 - beta2) * (db**2) #Bias\n",
        "\n",
        "  pre_v_dw = v_dw.copy()\n",
        "  pre_v_db = v_db.copy()\n",
        "\n",
        "  # bias correction\n",
        "  v_dw = v_dw / (1 - beta2**t)\n",
        "  v_db = v_db / (1 - beta2**t)\n",
        "\n",
        "  return v_dw , v_db"
      ],
      "metadata": {
        "id": "NUhgch7CWAUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96oamka7iCQl"
      },
      "outputs": [],
      "source": [
        "# Implemeting our activation Function (Sigmoid Function)\n",
        "def sigmoid(z):\n",
        "\n",
        "    sigmoid_fn = 1/ (1 + np.exp(-z))\n",
        "\n",
        "    return sigmoid_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wY40xgWjrhN"
      },
      "outputs": [],
      "source": [
        "# Implemeting the cross entropy\n",
        "def costFunction(x, y , alpha , w , b , lamda , optimize_val):\n",
        "\n",
        "    #Define Parameters needed for optimizers\n",
        "    t = 1\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    epsilon = 10e-8\n",
        "\n",
        "    z = np.dot(w, x.T) + b #Net-Input\n",
        "    phi = sigmoid(z) #Activation Function\n",
        "\n",
        "    #Cost function\n",
        "    cost = np.mean(-y * np.log(phi+epsilon) - (1 - y) * np.log(1 - phi+epsilon)) + (lamda * np.sum(abs(w)) / (2 * x.shape[0]))\n",
        "\n",
        "    #Compute Derivative\n",
        "    dj_dw = ((np.dot((phi - y).T, x)) / x.shape[0]) + ((lamda * np.sign(w))/(x.shape[0] * 2))\n",
        "    dj_db = (np.mean((phi - y)))\n",
        "\n",
        "    if optimize_val == 1:\n",
        "      #RMS prop Optimizer Function\n",
        "      v_dw , v_db = rms_prop(w , b , dj_dw , dj_db , t , beta2)\n",
        "\n",
        "      #Update Weights & Bias\n",
        "      w = w - (alpha * (dj_dw / (np.sqrt(v_dw + epsilon))))\n",
        "      b = b - (alpha * (dj_db / (np.sqrt(v_db + epsilon))))\n",
        "\n",
        "    else:\n",
        "      #AdaM Optimizer Function\n",
        "      m_dw , m_db = momentum(w , b , dj_dw , dj_db , t , beta1)\n",
        "      v_dw , v_db = rms_prop(w , b , dj_dw , dj_db , t , beta2)\n",
        "      #Update Weights & Bias\n",
        "      w = w - (alpha * ((m_dw) / (np.sqrt(v_dw + epsilon))))\n",
        "      b = b - (alpha * ((m_db) / (np.sqrt(v_db + epsilon))))\n",
        "\n",
        "    return cost , w , b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IWac-SLjtx1"
      },
      "outputs": [],
      "source": [
        "# Implementing the Logistic Regression\n",
        "def gradientDescent(X , Y , alpha , num_iterations):\n",
        "\n",
        "    #Define Parameters\n",
        "    cost = 0.0\n",
        "    w = np.random.randn(X.shape[1])\n",
        "    b = np.random.randn()\n",
        "\n",
        "    # Getting the lambda value from the user\n",
        "    lambda_val = float(input(\"\\nEnter the lambda value: \"))\n",
        "\n",
        "    # Getting the optimization method from the user\n",
        "    optimize_val = int(input(\"\\n1.RMS prop Optimizer \\n2.AdaM Optimizer \\nSelect one of the above optimizers: \"))\n",
        "\n",
        "    # Shuffle the data\n",
        "    n = X.shape[0]\n",
        "    batch_siz = int(input(\"\\nEnter the batch size: \")) # Getting the batch size from the user\n",
        "\n",
        "    num_batch = n // batch_siz\n",
        "    indices = np.arange(n)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Applying Mini-Batch\n",
        "    for i in range(num_iterations):\n",
        "      for batch in range(num_batch):\n",
        "        if batch!=num_batch-1:\n",
        "          start = batch * batch_siz\n",
        "          end = (batch + 1) * batch_siz\n",
        "\n",
        "          val_indices = indices[start:end]\n",
        "          train_indices = np.concatenate([indices[:start], indices[end:]])\n",
        "\n",
        "          X_train_batch = X[train_indices].copy()\n",
        "          Y_train_batch = Y[train_indices].copy()\n",
        "          X_val = X[val_indices]\n",
        "          Y_val = Y[val_indices]\n",
        "        else:\n",
        "          start = batch * batch_siz\n",
        "          end = ((batch + 1) * batch_siz) +(n % batch_siz)\n",
        "\n",
        "          val_indices = indices[start:end]\n",
        "          train_indices = np.concatenate([indices[:start], indices[end:]])\n",
        "\n",
        "          X_train_batch = X[train_indices].copy()\n",
        "          Y_train_batch = Y[train_indices].copy()\n",
        "          X_val = X[val_indices]\n",
        "          Y_val = Y[val_indices]\n",
        "\n",
        "        cost , w , b = costFunction(X_train_batch , Y_train_batch , alpha , w , b , lambda_val , optimize_val)\n",
        "        #print(\"Batch#: \" + str(batch) + \" , weight: \" + str(w) + \" , bias: \" + str(b))\n",
        "\n",
        "    return cost , w , b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE9J-0kACwCz"
      },
      "outputs": [],
      "source": [
        "# Function that calculates the prediction\n",
        "def predict(x, w, b):\n",
        "\n",
        "  z = np.dot(w, x.T) + b #Net-Input\n",
        "  result = sigmoid(z)\n",
        "\n",
        "  return np.where(result >= 0.5, 1, 0).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_37BN3YGXLtH"
      },
      "outputs": [],
      "source": [
        "def result_fn(X, Y):\n",
        "\n",
        "  cost , w , b = gradientDescent(X , Y , 0.01 , 20)\n",
        "  pred = predict(X , w , b)\n",
        "  accuracy_score = accuracy(pred , Y)\n",
        "  print(\"Learning Rate: \" + str(0.01) + \" , Accuracy: \" + str(accuracy_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfzMuhJalMgh",
        "outputId": "e4d25b4f-d200-4133-bc2e-7030995ee46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the lambda value: 0.01\n",
            "\n",
            "1.RMS prop Optimizer \n",
            "2.AdaM Optimizer \n",
            "Select one of the above optimizers: 1\n",
            "\n",
            "Enter the batch size: 64\n",
            "Learning Rate: 0.01 , Accuracy: 91.94630872483222\n"
          ]
        }
      ],
      "source": [
        "# Lambda value of 0.01\n",
        "result_fn(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lambda value of 0.1\n",
        "result_fn(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX9OOmiUH-oO",
        "outputId": "81d32242-32e9-4163-a31d-63f713f3b485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the lambda value: 0.1\n",
            "\n",
            "1.RMS prop Optimizer \n",
            "2.AdaM Optimizer \n",
            "Select one of the above optimizers: 1\n",
            "\n",
            "Enter the batch size: 64\n",
            "Learning Rate: 0.01 , Accuracy: 93.24121594946703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown from above, when we increased the the lambda value , the accuracy also increases"
      ],
      "metadata": {
        "id": "9bYw9B61JR9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Size of 64\n",
        "result_fn(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E5YajnPIVef",
        "outputId": "226dbabc-1f43-4cbf-cca5-3224c6eb9111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the lambda value: 0.01\n",
            "\n",
            "1.RMS prop Optimizer \n",
            "2.AdaM Optimizer \n",
            "Select one of the above optimizers: 1\n",
            "\n",
            "Enter the batch size: 64\n",
            "Learning Rate: 0.01 , Accuracy: 99.40781681800237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Size of 256\n",
        "result_fn(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCmAGTtlJwaV",
        "outputId": "ba6b88de-467a-466f-f5b7-b226466f38b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the lambda value: 0.01\n",
            "\n",
            "1.RMS prop Optimizer \n",
            "2.AdaM Optimizer \n",
            "Select one of the above optimizers: 1\n",
            "\n",
            "Enter the batch size: 256\n",
            "Learning Rate: 0.01 , Accuracy: 97.82866166600868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using RMS prop optimizer with lambda value of 0.01 and batch size of 64\n",
        "result_fn(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzGpgEKwKWV5",
        "outputId": "5440d596-c118-4f43-fd8a-dd28572e45cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the lambda value: 0.01\n",
            "\n",
            "1.RMS prop Optimizer \n",
            "2.AdaM Optimizer \n",
            "Select one of the above optimizers: 1\n",
            "\n",
            "Enter the batch size: 64\n",
            "Learning Rate: 0.01 , Accuracy: 99.58941966048164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Adam optimizer with lambda value of 0.01 and batch size of 64\n",
        "result_fn(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5vXAmHnKWq3",
        "outputId": "0fbdcf35-a615-460c-ada7-d78f3278f290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the lambda value: 0.01\n",
            "\n",
            "1.RMS prop Optimizer \n",
            "2.AdaM Optimizer \n",
            "Select one of the above optimizers: 2\n",
            "\n",
            "Enter the batch size: 64\n",
            "Learning Rate: 0.01 , Accuracy: 99.71575207264114\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}